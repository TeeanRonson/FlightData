{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "import statsmodels.formula.api as smf \n",
    "import statsmodels.api as sm\n",
    "import os\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Question1***\n",
    "\n",
    "Predicting flight delays using a dataset from the Bureau of Transportation Statistics\n",
    "\n",
    "Variables: \n",
    "    1. MONTH\n",
    "    2. DAY_OF_WEEK\n",
    "    3. FL_DATE (flight date)\n",
    "    4. UNIQUE_CARRIER\n",
    "    5. FL_NUM (flight number)\n",
    "    6. ORIGIN (airport code)\n",
    "    7. ORIGIN_CITY_NAME\n",
    "    8. DEST (airport code)\n",
    "    9. DEST_CITY_NAME\n",
    "    10. CRS_DEP_TIME (departure time)\n",
    "    11. ARR_DEL15 (arrival delay greater than 15 minutes â€” the target)\n",
    "    12. CRS_ELAPSED_TIME\n",
    "    13. DISTANCE (miles between origin and destination)|\n",
    "\n",
    "Given the independent variables above, I include only several variables for the remainder of my model in which I believe will deliver purposeful impact during prediction in this classification task. Conversely, I omit such variables in which I believe do not/will not serve as good predictors in the classification task. \n",
    "\n",
    "Included Independent variables:\n",
    "1. MONTH\n",
    "2. DAY_OF_WEEK\n",
    "3. FL_DATE (flight date)\n",
    "5. FL_NUM (flight number)\n",
    "6. ORIGIN (airport code)\n",
    "8. DEST (airport code)\n",
    "10. CRS_DEP_TIME (departure time)\n",
    "12. CRS_ELAPSED_TIME\n",
    "13. DISTANCE (miles between origin and destination)|\n",
    "\n",
    "Excluded variables:\n",
    "7. ORIGIN_CITY_NAME\n",
    "9. DEST_CITY_NAME\n",
    "\n",
    "The decision to exclude origin and destination city stems from the fact that it represents duplicate information when ORIGIN(airport code) and DEST(airport code) has already been taken into account in the model. \n",
    "\n",
    "This notebook will continue as follows: \n",
    "1. Data cleaning \n",
    "   - Clean data to only include relevant variables \n",
    "   - Check for any NaN values in the dataset. If they exist, replace the NaN cell with the most frequently observed value in the respective column using scikit-learn's Imputer. \n",
    "   - Convert String variables to numerical values using scikit-learn's Label Encoder.\n",
    "   - Consolidate dataset\n",
    "   \n",
    "2. Classification task\n",
    "   - Random Forest vs AdaBoost vs XG Boost \n",
    "   - results \n",
    "   - Conclusion & Discussion "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***1. Data Observation***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   MONTH  DAY_OF_WEEK     FL_DATE UNIQUE_CARRIER  FL_NUM ORIGIN  \\\n",
      "0    2.0          6.0  2017-02-25             B6    28.0    MCO   \n",
      "1    2.0          7.0  2017-02-26             B6    28.0    MCO   \n",
      "2    2.0          1.0  2017-02-27             B6    28.0    MCO   \n",
      "3    2.0          2.0  2017-02-28             B6    28.0    MCO   \n",
      "4    2.0          3.0  2017-02-01             B6    33.0    BTV   \n",
      "\n",
      "  ORIGIN_CITY_NAME DEST DEST_CITY_NAME  CRS_DEP_TIME  ARR_DEL15  \\\n",
      "0      Orlando, FL  EWR     Newark, NJ        1000.0        0.0   \n",
      "1      Orlando, FL  EWR     Newark, NJ         739.0        0.0   \n",
      "2      Orlando, FL  EWR     Newark, NJ        1028.0        0.0   \n",
      "3      Orlando, FL  EWR     Newark, NJ         739.0        0.0   \n",
      "4   Burlington, VT  JFK   New York, NY        1907.0        0.0   \n",
      "\n",
      "   CRS_ELAPSED_TIME  DISTANCE  Unnamed: 13  \n",
      "0             156.0     937.0          NaN  \n",
      "1             153.0     937.0          NaN  \n",
      "2             158.0     937.0          NaN  \n",
      "3             153.0     937.0          NaN  \n",
      "4              90.0     266.0          NaN  \n"
     ]
    }
   ],
   "source": [
    "os.getcwd()\n",
    "flightdata = pd.read_csv('/Users/Rong/Documents/USF/Machine Learning 2/MidTerm2/aggregated.csv')\n",
    "print(flightdata.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Checking data and cleaning***\n",
    "\n",
    "Due to the duplicity of ORIGIN_CITY_NAME and DEST_CITY_NAME, I will drop these two columns from the dataset. According to the analysis by the Bereau of Transportation Statistics, the most relevant information regarding the complex organisation of flights is 'Airport code'. This is due to the fact that there could be multiple airports within the same city. As such, I conjecture that the city name will not deliver any additional information gain for the purposes of this classification task. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   MONTH  DAY_OF_WEEK     FL_DATE UNIQUE_CARRIER  FL_NUM ORIGIN DEST  \\\n",
      "0    2.0          6.0  2017-02-25             B6    28.0    MCO  EWR   \n",
      "1    2.0          7.0  2017-02-26             B6    28.0    MCO  EWR   \n",
      "2    2.0          1.0  2017-02-27             B6    28.0    MCO  EWR   \n",
      "3    2.0          2.0  2017-02-28             B6    28.0    MCO  EWR   \n",
      "4    2.0          3.0  2017-02-01             B6    33.0    BTV  JFK   \n",
      "\n",
      "   CRS_DEP_TIME  ARR_DEL15  CRS_ELAPSED_TIME  DISTANCE  \n",
      "0        1000.0        0.0             156.0     937.0  \n",
      "1         739.0        0.0             153.0     937.0  \n",
      "2        1028.0        0.0             158.0     937.0  \n",
      "3         739.0        0.0             153.0     937.0  \n",
      "4        1907.0        0.0              90.0     266.0  \n"
     ]
    }
   ],
   "source": [
    "data = flightdata.iloc[:,:-1]\n",
    "data = data.drop(['ORIGIN_CITY_NAME', 'DEST_CITY_NAME'], axis =1)\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Checking for null values***\n",
    "\n",
    "Operation to check if there are any Null values int the dataset provided. \n",
    "\n",
    "If return True - Null values exist and we search for columns with null values\n",
    "\n",
    "If return False - Null values do not exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null values exists? --> True\n"
     ]
    }
   ],
   "source": [
    "print('Null values exists? --> ' +  str(data.isnull().values.any()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARR_DEL15\n",
      "8\n",
      "CRS_ELAPSED_TIME\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "count = -1\n",
    "for i in data.columns:\n",
    "    count = count + 1\n",
    "    if data[i].isnull().values.any() == True:\n",
    "        print(i)\n",
    "        print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Data cleaning***\n",
    "\n",
    "We extract values the columns with NaN values and fill in the cells using the Scikit-learn' Imputer. \n",
    "\n",
    "For the purposes of this model, we use 'most frequent' as the value to be filled. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract Y from data \n",
    "Y = data.iloc[:, 8]\n",
    "Y = Y.to_frame(name=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract crs_elapsed_time from X\n",
    "crs_elapsed_time = data.iloc[:, 9]\n",
    "crs_elapsed_time = crs_elapsed_time.to_frame(name=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "imputer = Imputer(missing_values = 'NaN', strategy = 'most_frequent', axis = 0)\n",
    "\n",
    "Y_imputed = imputer.fit_transform(Y)\n",
    "crs_elapsed_time_imputed = imputer.fit_transform(crs_elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Place crs_elapsed_time back into X \n",
    "data.iloc[:, 8] = Y_imputed\n",
    "data.iloc[:, 9] = crs_elapsed_time_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def encode_labels(labels):\n",
    "    \n",
    "    from sklearn import preprocessing \n",
    "    \n",
    "    le = preprocessing.LabelEncoder()\n",
    "    \n",
    "    return le.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***We convert columns with String formats into numerical values*** \n",
    "\n",
    "This is purely for the purpose of modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   MONTH  DAY_OF_WEEK  FL_DATE  UNIQUE_CARRIER  FL_NUM  ORIGIN  DEST  \\\n",
      "0    2.0          6.0      330               2    28.0     188    98   \n",
      "1    2.0          7.0      331               2    28.0     188    98   \n",
      "2    2.0          1.0      332               2    28.0     188    98   \n",
      "3    2.0          2.0      333               2    28.0     188    98   \n",
      "4    2.0          3.0      306               2    33.0      48   158   \n",
      "\n",
      "   CRS_DEP_TIME  ARR_DEL15  CRS_ELAPSED_TIME  DISTANCE  \n",
      "0        1000.0        0.0             156.0     937.0  \n",
      "1         739.0        0.0             153.0     937.0  \n",
      "2        1028.0        0.0             158.0     937.0  \n",
      "3         739.0        0.0             153.0     937.0  \n",
      "4        1907.0        0.0              90.0     266.0  \n"
     ]
    }
   ],
   "source": [
    "#Label encode selected X columns \n",
    "fl_date = data.loc[:, 'FL_DATE']\n",
    "unique_carrier = data.loc[:,'UNIQUE_CARRIER']\n",
    "origin = data.loc[:,'ORIGIN']\n",
    "dest = data.loc[:,'DEST']\n",
    "\n",
    "fl_date_lbl = encode_labels(fl_date)\n",
    "unique_carrier_lbl = encode_labels(unique_carrier)\n",
    "origin_lbl = encode_labels(origin)\n",
    "dest_lbl = encode_labels(dest)\n",
    "\n",
    "data.loc[:, 'FL_DATE'] = fl_date_lbl\n",
    "data.loc[:,'UNIQUE_CARRIER'] = unique_carrier_lbl\n",
    "data.loc[:,'ORIGIN'] = origin_lbl\n",
    "data.loc[:,'DEST'] = dest_lbl\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Finalise X and Y to be used in the learning process***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Finalise data\n",
    "ready_X = data.drop(['ARR_DEL15'], axis =1)\n",
    "# print(ready_X.head())\n",
    "ready_Y = data.iloc[:,8]\n",
    "# print(ready_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***2. Classification Task***\n",
    "\n",
    "I have decided to use Random Forest and compare its results against XGBoost and AdaBoost for several reasons. \n",
    "\n",
    "**Random Forest**\n",
    "\n",
    "Firstly, due to the robustness of the Random Forest algorithm, I believe this serves as a good first shot attempt at predicting flight delays. Further, given the vastness of the dataset, I believe an ensemble method will be robust since we will be able to lower the variance in the data due to the bagging characteristic of this algorithm. This also prevents overfit. \n",
    "\n",
    "**Adaboost**\n",
    "\n",
    "I then use Adaboost in an attempt to boost the robustness of the results in Random Forest. As the 'weak learners' is combined into a weighted sum, this will aid the final output of the boosted classifier - subsequent weak learners are tweaked in favor of those instances misclassified by previous classifiers and so given higher preference. Finally, I use this as it will be less susceptible to the overfitting problem in comparision to Random Forest in singleton.\n",
    "\n",
    "**XGBoost**\n",
    "\n",
    "This is used to contrast with Adaboost. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Random Forest***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Rong/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/Rong/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/Rong/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/Rong/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/Rong/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/Rong/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "clf1 = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', max_features = 'auto', max_depth = 6, bootstrap = True, random_state = 1)\n",
    "cv_rf = cross_validate(clf1, X=ready_X, y=ready_Y, cv=10, scoring=['accuracy', 'recall', 'roc_auc', 'precision'])\n",
    "#Place into dataframe\n",
    "cv_rf_df = pd.DataFrame(cv_rf)\n",
    "cv_rf_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***XGBoost***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Rong/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/Rong/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/Rong/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/Rong/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "clf2 = XGBClassifier(n_estimators=10, max_depth=6, learning_rate=0.1, subsample=0.5, random_state=1)\n",
    "cv_xg = cross_validate(clf2, X=ready_X, y=ready_Y, cv=10, scoring=['accuracy', 'recall', 'roc_auc', 'precision'])\n",
    "#Place into dataframe\n",
    "cv_xg_df = pd.DataFrame(cv_xg)\n",
    "cv_xg_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Rong/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('train_accuracy'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/Rong/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('train_precision'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/Rong/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('train_recall'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/Rong/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('train_roc_auc'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_roc_auc</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>train_roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>47.263188</td>\n",
       "      <td>1.578935</td>\n",
       "      <td>0.822380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.489290</td>\n",
       "      <td>0.822737</td>\n",
       "      <td>0.720096</td>\n",
       "      <td>0.003282</td>\n",
       "      <td>0.676369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45.621868</td>\n",
       "      <td>1.572849</td>\n",
       "      <td>0.723743</td>\n",
       "      <td>0.051359</td>\n",
       "      <td>0.031787</td>\n",
       "      <td>0.459767</td>\n",
       "      <td>0.824119</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.009787</td>\n",
       "      <td>0.671549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44.828410</td>\n",
       "      <td>1.478678</td>\n",
       "      <td>0.574097</td>\n",
       "      <td>0.113976</td>\n",
       "      <td>0.206362</td>\n",
       "      <td>0.427419</td>\n",
       "      <td>0.828615</td>\n",
       "      <td>0.933038</td>\n",
       "      <td>0.037810</td>\n",
       "      <td>0.678065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47.085224</td>\n",
       "      <td>1.540048</td>\n",
       "      <td>0.701412</td>\n",
       "      <td>0.037865</td>\n",
       "      <td>0.027901</td>\n",
       "      <td>0.300049</td>\n",
       "      <td>0.824196</td>\n",
       "      <td>0.936283</td>\n",
       "      <td>0.010968</td>\n",
       "      <td>0.682720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45.941356</td>\n",
       "      <td>1.442077</td>\n",
       "      <td>0.822381</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.321226</td>\n",
       "      <td>0.822381</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.673167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>49.019903</td>\n",
       "      <td>1.541995</td>\n",
       "      <td>0.759404</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.599130</td>\n",
       "      <td>0.826236</td>\n",
       "      <td>0.992473</td>\n",
       "      <td>0.021870</td>\n",
       "      <td>0.666032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>48.929838</td>\n",
       "      <td>1.613355</td>\n",
       "      <td>0.815920</td>\n",
       "      <td>0.340305</td>\n",
       "      <td>0.038757</td>\n",
       "      <td>0.606808</td>\n",
       "      <td>0.822415</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>0.670670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>46.867644</td>\n",
       "      <td>1.608480</td>\n",
       "      <td>0.822381</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.649863</td>\n",
       "      <td>0.822381</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>47.943345</td>\n",
       "      <td>1.544320</td>\n",
       "      <td>0.822381</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.604839</td>\n",
       "      <td>0.822535</td>\n",
       "      <td>0.745003</td>\n",
       "      <td>0.001318</td>\n",
       "      <td>0.672980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>45.742939</td>\n",
       "      <td>1.715453</td>\n",
       "      <td>0.313133</td>\n",
       "      <td>0.205462</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.582828</td>\n",
       "      <td>0.823809</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.008039</td>\n",
       "      <td>0.660594</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    fit_time  score_time  test_accuracy  test_precision  test_recall  \\\n",
       "0  47.263188    1.578935       0.822380        0.000000     0.000000   \n",
       "1  45.621868    1.572849       0.723743        0.051359     0.031787   \n",
       "2  44.828410    1.478678       0.574097        0.113976     0.206362   \n",
       "3  47.085224    1.540048       0.701412        0.037865     0.027901   \n",
       "4  45.941356    1.442077       0.822381        0.000000     0.000000   \n",
       "5  49.019903    1.541995       0.759404        0.000000     0.000000   \n",
       "6  48.929838    1.613355       0.815920        0.340305     0.038757   \n",
       "7  46.867644    1.608480       0.822381        0.000000     0.000000   \n",
       "8  47.943345    1.544320       0.822381        0.000000     0.000000   \n",
       "9  45.742939    1.715453       0.313133        0.205462     1.000000   \n",
       "\n",
       "   test_roc_auc  train_accuracy  train_precision  train_recall  train_roc_auc  \n",
       "0      0.489290        0.822737         0.720096      0.003282       0.676369  \n",
       "1      0.459767        0.824119         1.000000      0.009787       0.671549  \n",
       "2      0.427419        0.828615         0.933038      0.037810       0.678065  \n",
       "3      0.300049        0.824196         0.936283      0.010968       0.682720  \n",
       "4      0.321226        0.822381         0.000000      0.000000       0.673167  \n",
       "5      0.599130        0.826236         0.992473      0.021870       0.666032  \n",
       "6      0.606808        0.822415         1.000000      0.000191       0.670670  \n",
       "7      0.649863        0.822381         0.000000      0.000000       0.666794  \n",
       "8      0.604839        0.822535         0.745003      0.001318       0.672980  \n",
       "9      0.582828        0.823809         1.000000      0.008039       0.660594  "
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***AdaBoost***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Rong/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/Rong/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/Rong/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/Rong/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/Rong/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/Rong/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/Rong/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/Rong/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/Rong/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/Rong/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "clf3 = AdaBoostClassifier(n_estimators=10, learning_rate= 0.1, random_state=1)\n",
    "cv_ab = cross_validate(clf3, X=ready_X, y=ready_Y, cv=10, scoring=['accuracy', 'recall', 'roc_auc', 'precision'])\n",
    "#Place into dataframe\n",
    "cv_ab_df = pd.DataFrame(cv_ab)\n",
    "cv_ab_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Evaluation***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results delivered by all three classifiers show strength in the test_accuracy with an average above 0.80, however, the continous upset in precision and recall leads me to believe that the results may be continously skewed. \n",
    "\n",
    "Precision is the fraction of relevant instances among the retrieved instances.\n",
    "\n",
    "Recall is the fraction of relevant instances that have been retrieved over the total amount of relevant instances.\n",
    "\n",
    "In general we want to aim for high precision and high recall since Precision tell us how useful the search results are and Recall is how complete the results are. However, the consistent values edging around the 0 mark makes me believe that:\n",
    "\n",
    "1. Precision the algorithm did not return any substantially relevant results than irrelevant ones\n",
    "\n",
    "2. Recall means that an algorithm returned none of the relevant results.\n",
    "\n",
    "Further analysis finds that there is huge imbalance of delayed instances when compared to not-delayed instances. Specifically it is 1:4 at 0.21%. \n",
    "\n",
    "\n",
    "As such the approach I take is to curate a balanced dataset, approximately in the ratio of 1:1 and re-run this data. This should adjust to deliver more accurate results in predicting flight delays. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Observing the imbalance in the dataset***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "911071\n",
      "4218283\n",
      "0.2159814787201333\n"
     ]
    }
   ],
   "source": [
    "delayed = ready_Y[ready_Y == 1]\n",
    "notdelayed = ready_Y[ready_Y == 0]\n",
    "print(len(delayed))\n",
    "print(len(notdelayed))\n",
    "print(len(delayed)/len(notdelayed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Creating a balanced dataset***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "delayed = data[data['ARR_DEL15'] == 1]\n",
    "notdelayed = data[data['ARR_DEL15'] == 0]\n",
    "\n",
    "notdelayed = notdelayed.sample(n=911071, replace=False, random_state=1)\n",
    "frames = [delayed, notdelayed]\n",
    "data_adjusted = pd.concat(frames)\n",
    "\n",
    "new_X = data_adjusted.drop(['ARR_DEL15'], axis =1)\n",
    "new_Y = data_adjusted.loc[:,'ARR_DEL15']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Running Random Forest, AdaBoost and XGBoost with the datasert***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Random Forest***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fit_time  score_time  test_accuracy  test_precision  test_recall  \\\n",
      "0  27.215166    0.686914       0.295720        0.000644     0.000263   \n",
      "1  25.282983    0.692719       0.294818        0.009396     0.003929   \n",
      "2  26.106565    0.678356       0.346999        0.200116     0.102100   \n",
      "3  24.940020    0.669907       0.296388        0.028325     0.012227   \n",
      "4  25.624852    0.677847       0.297299        0.041192     0.018198   \n",
      "5  24.743069    0.629626       0.447260        0.437825     0.371387   \n",
      "6  25.256049    0.675231       0.365768        0.263283     0.149297   \n",
      "7  24.948683    0.854897       0.296624        0.001480     0.000604   \n",
      "8  25.011014    0.712125       0.319119        0.109500     0.050721   \n",
      "9  25.776631    0.660226       0.291449        0.000000     0.000000   \n",
      "\n",
      "   test_roc_auc  train_accuracy  train_precision  train_recall  train_roc_auc  \n",
      "0      0.100928        0.640439         0.628081      0.688682       0.698949  \n",
      "1      0.144867        0.624719         0.616227      0.661249       0.681215  \n",
      "2      0.213941        0.621353         0.614185      0.652738       0.675751  \n",
      "3      0.084613        0.637303         0.623582      0.692815       0.695691  \n",
      "4      0.131045        0.622450         0.611537      0.671373       0.675788  \n",
      "5      0.419212        0.614261         0.596857      0.704102       0.661856  \n",
      "6      0.361246        0.618064         0.610830      0.650699       0.669753  \n",
      "7      0.155099        0.623721         0.616216      0.656011       0.683074  \n",
      "8      0.127611        0.638213         0.625679      0.688081       0.699931  \n",
      "9      0.039113        0.622977         0.614045      0.662134       0.679060  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Rong/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('train_accuracy'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/Rong/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('train_precision'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/Rong/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('train_recall'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/Rong/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('train_roc_auc'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    }
   ],
   "source": [
    "clf4 = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', max_features = 'auto', max_depth = 6, bootstrap = True, random_state = 1)\n",
    "cv_rf_new = cross_validate(clf4, X=new_X, y=new_Y, cv=10, scoring=['accuracy', 'recall', 'roc_auc', 'precision'])\n",
    "cv_rf_df_new = pd.DataFrame(cv_rf_new)\n",
    "print(cv_rf_df_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***XGBoost***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fit_time  score_time  test_accuracy  test_precision  test_recall  \\\n",
      "0  27.796455    0.590970       0.291292        0.000000     0.000000   \n",
      "1  29.469010    0.590980       0.301228        0.042539     0.018484   \n",
      "2  26.577532    0.681694       0.346099        0.176111     0.083682   \n",
      "3  27.913726    0.560564       0.293841        0.008736     0.003666   \n",
      "4  29.179602    0.734634       0.292985        0.029910     0.013171   \n",
      "5  30.072061    0.677029       0.356592        0.248416     0.141603   \n",
      "6  28.792837    0.664532       0.376041        0.291821     0.173763   \n",
      "7  30.588181    0.662444       0.312232        0.053971     0.022721   \n",
      "8  28.356149    0.620402       0.314460        0.108178     0.051225   \n",
      "9  28.596966    0.669398       0.284753        0.000280     0.000121   \n",
      "\n",
      "   test_roc_auc  train_accuracy  train_precision  train_recall  train_roc_auc  \n",
      "0      0.082561        0.643737         0.628510      0.702981       0.703116  \n",
      "1      0.099527        0.637010         0.624125      0.688913       0.695142  \n",
      "2      0.206765        0.630103         0.624296      0.653460       0.685264  \n",
      "3      0.061781        0.642661         0.627967      0.700075       0.704614  \n",
      "4      0.064637        0.632031         0.617733      0.692754       0.688957  \n",
      "5      0.290973        0.625886         0.613721      0.679371       0.677184  \n",
      "6      0.277446        0.628688         0.617177      0.677804       0.683783  \n",
      "7      0.133320        0.638108         0.629014      0.673353       0.694264  \n",
      "8      0.107214        0.649033         0.631118      0.717350       0.709519  \n",
      "9      0.042782        0.628209         0.615066      0.685317       0.686186  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Rong/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('train_accuracy'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/Rong/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('train_precision'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/Rong/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('train_recall'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/Rong/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('train_roc_auc'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    }
   ],
   "source": [
    "clf5 = XGBClassifier(n_estimators=10, max_depth=6, learning_rate=0.1, subsample=0.5)\n",
    "cv_xg_new = cross_validate(clf5, X=new_X, y=new_Y, cv=10, scoring=['accuracy', 'recall', 'roc_auc', 'precision'])\n",
    "cv_xg_df_new = pd.DataFrame(cv_xg_new)\n",
    "print(cv_xg_df_new)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***AdaBoost***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fit_time  score_time  test_accuracy  test_precision  test_recall  \\\n",
      "0  22.664850    1.008154       0.350183        0.275261     0.183497   \n",
      "1  22.904869    0.828423       0.292047        0.000000     0.000000   \n",
      "2  21.729513    0.823942       0.418568        0.394584     0.304806   \n",
      "3  19.331246    0.818641       0.286822        0.000000     0.000000   \n",
      "4  23.310710    0.838609       0.578177        0.567672     0.655800   \n",
      "5  25.725943    0.791487       0.605277        0.582643     0.742215   \n",
      "6  19.702431    0.710503       0.599098        0.579773     0.720219   \n",
      "7  21.279591    0.752411       0.578973        0.566110     0.676260   \n",
      "8  21.712049    0.763443       0.555457        0.550604     0.603400   \n",
      "9  21.145820    0.755412       0.257450        0.000000     0.000000   \n",
      "\n",
      "   test_roc_auc  train_accuracy  train_precision  train_recall  train_roc_auc  \n",
      "0      0.207474        0.608826         0.591814      0.701469       0.639188  \n",
      "1      0.311898        0.606192         0.601952      0.626989       0.632723  \n",
      "2      0.324397        0.601423         0.588806      0.672461       0.623705  \n",
      "3      0.111904        0.611379         0.603358      0.650182       0.639293  \n",
      "4      0.477539        0.585171         0.572495      0.672594       0.615003  \n",
      "5      0.588002        0.581157         0.566606      0.690385       0.608400  \n",
      "6      0.583739        0.582412         0.568368      0.685120       0.609537  \n",
      "7      0.528094        0.584415         0.570098      0.686536       0.616695  \n",
      "8      0.462270        0.589169         0.576552      0.671575       0.624417  \n",
      "9      0.047518        0.605338         0.589401      0.694468       0.630186  \n",
      "<bound method Series.mean of 0    0.350183\n",
      "1    0.292047\n",
      "2    0.418568\n",
      "3    0.286822\n",
      "4    0.578177\n",
      "5    0.605277\n",
      "6    0.599098\n",
      "7    0.578973\n",
      "8    0.555457\n",
      "9    0.257450\n",
      "Name: test_accuracy, dtype: float64>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Rong/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('train_accuracy'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/Rong/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('train_precision'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/Rong/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('train_recall'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/Rong/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('train_roc_auc'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    }
   ],
   "source": [
    "clf6 = AdaBoostClassifier(n_estimators=10, learning_rate= 0.1)\n",
    "cv_ab_new = cross_validate(clf6, X=new_X, y=new_Y, cv=10, scoring=['accuracy', 'recall', 'roc_auc', 'precision'])\n",
    "cv_ab_df_new = pd.DataFrame(cv_ab_new)\n",
    "print(cv_ab_df_new)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Conclusion***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, although adjusting the dataset decreases the prediction accuracy score significantly. Specifically by 50%. I believe these results are more representative of the dataset and thus giving the reader a more representative and holistic view in predicting flight delays.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45220526393877647\n"
     ]
    }
   ],
   "source": [
    "print(cv_ab_df_new['test_accuracy'].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
